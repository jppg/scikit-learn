{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "0b2cea495411c489d94b2cd6bc064cffb160e3e76c8325e417ea865657c8ce0c"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sentiment:\n",
    "    NEGATIVE = \"NEGATIVE\"\n",
    "    NEUTRAL = \"NEUTRAL\"\n",
    "    POSITIVE = \"POSITIVE\""
   ]
  },
  {
   "source": [
    "class Review:\n",
    "    def __init__(self, text, score):\n",
    "        self.text = text\n",
    "        self.score = score\n",
    "        self.sentiment = self.get_sentiment()\n",
    "\n",
    "    def get_sentiment(self):\n",
    "        if self.score <= 2:\n",
    "            return Sentiment.NEGATIVE\n",
    "        elif self.score == 3:\n",
    "            return Sentiment.NEUTRAL\n",
    "        else: #Score 4 or 5\n",
    "            return Sentiment.POSITIVE"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 19,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = './data/sentiment/Books_small.json'\n",
    "reviews = []\n",
    "\n",
    "with open(file_name) as f:\n",
    "    for line in f:\n",
    "        review = json.loads(line)\n",
    "        reviews.append(Review(review['reviewText'], review['overall']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'POSITIVE'"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "reviews[5].sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Prep Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "training, test = train_test_split(reviews, test_size=0.33, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "POSITIVE\n"
     ]
    }
   ],
   "source": [
    "print(training[0].sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = [x.text for x in training]\n",
    "train_y = [x.sentiment for x in training]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "\"Vivid characters and descriptions. The author has created a tale that grabs your attention and I couldn't put it down.\""
      ]
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "source": [
    "train_x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = [x.text for x in test]\n",
    "test_y = [x.sentiment for x in test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "\"Every new Myke Cole book is better than the last, and this is no exception. If you haven't read the Shadow Ops series before start with Control Point, but go ahead and order Fortress Frontier and Breach Zone as well - you're going to want them.\""
      ]
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "source": [
    "test_x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Bag of words vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_vectors = vectorizer.fit_transform(train_x)\n",
    "test_x_vectors = vectorizer.transform(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array(['POSITIVE'], dtype='<U8')"
      ]
     },
     "metadata": {},
     "execution_count": 68
    }
   ],
   "source": [
    "#### Linear SVM\n",
    "from sklearn import svm\n",
    "\n",
    "clf_svm = svm.SVC(kernel='linear')\n",
    "\n",
    "clf_svm.fit(train_x_vectors, train_y)\n",
    "\n",
    "clf_svm.predict(test_x_vectors[6])\n",
    "#3, 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array(['NEUTRAL'], dtype='<U8')"
      ]
     },
     "metadata": {},
     "execution_count": 67
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "clf_dtc = DecisionTreeClassifier()\n",
    "\n",
    "clf_dtc.fit(train_x_vectors, train_y)\n",
    "clf_dtc.predict(test_x_vectors[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "A sparse matrix was passed, but dense data is required. Use X.toarray() to convert to a dense numpy array.",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-90-436b65d91c9d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnaive_bayes\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mGaussianNB\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mclf_gnb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGaussianNB\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mclf_gnb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_x_vectors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;31m#clf_gnb.fit(train_x_vectors, train_y)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m#clf_gnb.predict(test_x_vectors[6])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Applics\\Python\\Python38\\lib\\site-packages\\sklearn\\naive_bayes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    205\u001b[0m         \u001b[0mself\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    206\u001b[0m         \"\"\"\n\u001b[1;32m--> 207\u001b[1;33m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    208\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwarn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    209\u001b[0m         return self._partial_fit(X, y, np.unique(y), _refit=True,\n",
      "\u001b[1;32mC:\\Applics\\Python\\Python38\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    431\u001b[0m                 \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    432\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 433\u001b[1;33m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    434\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    435\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Applics\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Applics\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m    812\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"y cannot be None\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    813\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 814\u001b[1;33m     X = check_array(X, accept_sparse=accept_sparse,\n\u001b[0m\u001b[0;32m    815\u001b[0m                     \u001b[0maccept_large_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maccept_large_sparse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    816\u001b[0m                     \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Applics\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Applics\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    591\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0missparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    592\u001b[0m         \u001b[0m_ensure_no_complex_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 593\u001b[1;33m         array = _ensure_sparse_format(array, accept_sparse=accept_sparse,\n\u001b[0m\u001b[0;32m    594\u001b[0m                                       \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    595\u001b[0m                                       \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mforce_all_finite\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Applics\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_ensure_sparse_format\u001b[1;34m(spmatrix, accept_sparse, dtype, copy, force_all_finite, accept_large_sparse)\u001b[0m\n\u001b[0;32m    358\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    359\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0maccept_sparse\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 360\u001b[1;33m         raise TypeError('A sparse matrix was passed, but dense '\n\u001b[0m\u001b[0;32m    361\u001b[0m                         \u001b[1;34m'data is required. Use X.toarray() to '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    362\u001b[0m                         'convert to a dense numpy array.')\n",
      "\u001b[1;31mTypeError\u001b[0m: A sparse matrix was passed, but dense data is required. Use X.toarray() to convert to a dense numpy array."
     ]
    }
   ],
   "source": [
    "#### Naive Bayes\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "clf_gnb = GaussianNB()\n",
    "clf_gnb.fit(train_x_vectors, train_y)\n",
    "#clf_gnb.fit(train_x_vectors, train_y)\n",
    "#clf_gnb.predict(test_x_vectors[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Applics\\Python\\Python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array(['POSITIVE'], dtype='<U8')"
      ]
     },
     "metadata": {},
     "execution_count": 91
    }
   ],
   "source": [
    "#### Logistic Regression\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf_lr = LogisticRegression()\n",
    "clf_lr.fit(train_x_vectors, train_y)\n",
    "clf_lr.predict(test_x_vectors[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(35) NEGATIVE  /  I guess I am not intellectual enough to appreciate this book.I have read every Larry McMurtry book on the old west ( He won the Pulitzer for Lonesome Dove so is no amateur here ) and enjoyed every minute ... probably because I liked the characters.&#34;Onion&#34; is the single most annoying character in this book and sadly he/she is the chosen narrator ... for me, an unreliable and unlikeable one.The book also needed an editor ... it went in pointless circles and could have been much more interesting with about 100 less pages of repetition.\nSupport Vector Machine:  ['POSITIVE']\nDecision Tree:  ['NEGATIVE']\n-------\n(55) NEGATIVE  /  I read a sample and it seemed ok.  The price was pretty high.  Took a chance and sad that I did.  Main characters were total idiots. Felt like my kid wrote his S***.  Refund please!\nSupport Vector Machine:  ['NEUTRAL']\nDecision Tree:  ['POSITIVE']\n-------\n(63) NEGATIVE  /  I did not get past three pages of this book because the f bomb was used so much i was distracted from the story line and decided not to waste any time going any further with the book if i could not get past the first three pages aggravated with the profanity\nSupport Vector Machine:  ['NEGATIVE']\nDecision Tree:  ['POSITIVE']\n-------\n(80) NEGATIVE  /  The content is great, but the printing of the book is terrible. The book looks like a photocopied version of the real book. For this price, I was hoping for a better print quality.\nSupport Vector Machine:  ['POSITIVE']\nDecision Tree:  ['POSITIVE']\n-------\n(89) NEGATIVE  /  the book was well written but the story line is lacking any depth.  It was fast and totally predictable and even the sex was very fast and unemotional.\nSupport Vector Machine:  ['POSITIVE']\nDecision Tree:  ['POSITIVE']\n-------\n(123) NEGATIVE  /  I think the book could have been great if the author could have decided what kind of book she wanted to write.  She has awesome descriptions, too vivid personal parts, great informational parts, poorly organized presentation.  I understood what she was aiming for, but the journey was not fun.  Will not read her again!\nSupport Vector Machine:  ['POSITIVE']\nDecision Tree:  ['NEUTRAL']\n-------\n(132) NEGATIVE  /  I enjoyed the first two books in this series.  Nothing earth shattering, but an enjoyable, casual read..  I also bought the audible versions so I could listen on the go.  Got to the 3rd book and ... it isn't complete - I mean, it just ... stops.  So basically, you get 2 stories that are pretty decent then a longish series of chapters with an author's note at the end that there is more to come (after you shell out more $$ of course.)  If you want resolutions to a number of plot lines, you have buy book 4.  There doesn't seem to be an expected date for that installment.I expect, at this price ($23 + audio), to find a beginning, middle and end to EACH book, not a bait and switch for the next installment.  This made me so mad that I returned the book to Amazon - which I have never done before. I say steer clear - very poorly done.\nSupport Vector Machine:  ['NEUTRAL']\nDecision Tree:  ['POSITIVE']\n-------\n(140) NEGATIVE  /  Originally a good tool to get teens to begin career exploration, this might proceed a bit to slowly to keep today's young people interested.  While the concepts are still relevant, the over stimulated youth of today need a quicker layout of the facts.I was taken aback that this text remained loaded with typos and grammatical errors.\nSupport Vector Machine:  ['NEUTRAL']\nDecision Tree:  ['POSITIVE']\n-------\n(147) NEGATIVE  /  Have not read it, so not sure if its good or not.  I installed it in my cellphone and tablet, but never read it.\nSupport Vector Machine:  ['NEGATIVE']\nDecision Tree:  ['POSITIVE']\n-------\n(152) NEGATIVE  /  I thought the title sounded fun. Unfortunately the book was awful.  What could have been a fun empowering book featuring full figure women turned out to have a pathetic train wreck.  The main character had such low self esteem there is no way she'd ever have a dating business.  She kept continually stating how \"guys like him wouldn't fall for a heavy girl.\"  Wow. This author has no idea the opportunity she had to show a strong confident larger woman who knew she was worth a lot and didn't need a man to define her. Skip this book it's too full of bad characters and self loathing and no redeeming value because the author further perpetuates the stereotype that full figure women would never attract a good looking man and if she did she was so lucky.  It should never only be about looks.  What a wasted opportunity for this author.\nSupport Vector Machine:  ['POSITIVE']\nDecision Tree:  ['POSITIVE']\n-------\n(153) NEGATIVE  /  I hated the storyline. It was a free book, and I did complete it,but I would not reread again. Stories that romanticize cheating on your spouse are not enjoyable to me.\nSupport Vector Machine:  ['NEUTRAL']\nDecision Tree:  ['NEUTRAL']\n-------\n(260) NEGATIVE  /  Repetitive. The entire 2nd book is basically the exact same thing as the 1st book. Someone is taken and they have to get them back... blah blah blah. Not worth your time. Please god, don't waste time on this mess like I did.\nSupport Vector Machine:  ['POSITIVE']\nDecision Tree:  ['POSITIVE']\n-------\n(291) NEGATIVE  /  We all remember that Hillary lost to Obama in 2008. In 'Hard Choices' she tells us that she then planned to return to the Senate and was surprised when Obama offered the Secretary of State position to her. Supposedly she liked the idea of following one of her heroes, William Seward - another N.Y. senator who lost out to the ultimate president (Lincoln), and then served in his cabinet. (Who ever heard of William Seward? And why the focus on 'political heroes' instead of the opportunity to better America?) We're supposed to believe that personal political calculation had nothing to do with her acceptance - 'When your President asks you to serve, you should say Yes.'Hillary's narration shows her as consistently hawkish, consistent with her previously insisting on serving on the Armed Services Committee while a senator, and voting for the Iraq War. But I also saw her as constantly sticking her nose into every other nation's affairs - to the point she came across as domineering and insulting; not surprisingly, she doesn't see it that way in 'Hard Choices.'As for Benghazi, it's lot of double-talk, taking all positions at the same time, but failing to address the question of 'Why did the U.S. even have a State Dept. office in a non-capital city in Libya?' Putin - he's a bad guy, but she fails to see that his help is essential in addressing problems in Syria and Iran, issues with Russian hackers interfering with U.S. commerce and Internet traffic, and probably Iraq. Thus, her/our demonizing him (and others) simply makes progress in other areas more difficult, if not impossible. Pivoting to Asia - another demonizing tactic that supposedly makes America (and Hillary) look tough, but makes little sense. Today we're seeking help from Iran to stem the Sunni uprising in Iraq. We need China's ongoing help (and that of others) to address Global Warming; on the other hand, we also need to stop letting Asia in general (and China in particular) decimate our economy. Free Trade is working - for them, not us. Regardless, who in America wants to risk losing eg. L.A. and Seattle to defend some miniscule island in the Pacific, thousands of miles away?We also get the cloy ploy for sympathy - 'there's a double standard applied to women in politics.' Tell that to Angela Merkel and others.Overall, 'Hard Choices' is rather boring and overly vague on specifics. Meanwhile, her political spin continues - this week it's a lame explanation of why she charges so much for speaking engagements.If anybody out there doesn't think 'Hard Choices' isn't a planned step on the road to the 2016 nomination, I've got a lot of bridges I'd like to sell you.\nSupport Vector Machine:  ['NEGATIVE']\nDecision Tree:  ['NEUTRAL']\n-------\n(295) NEGATIVE  /  Seriously... I do not know why I even read it. This book was downhill from the others (which is saying something because book 6 was downhill too....)I don't know... can I say Dexter seemed out of character? True, he's Jeff Lindsay's character, he should know how to write it...but it really seemed wrong. Like someone else wrote it. Or he wrote it to make someone else happy. I don't know. Blarg.\nSupport Vector Machine:  ['POSITIVE']\nDecision Tree:  ['POSITIVE']\n-------\n(303) NEGATIVE  /  Unfortunately, Fix You was not for me. I have been known to enjoy the serial books that are becoming a &#34;thing&#34; but, I think this book would have been better off sitting a little bit longer and coming out as a full story and not pieced out. I feel that the serials are meant for very emotional, and raw stories. Fix You didn't accomplish that with me. It felt disjointed and very rushed. I could not bring myself to like the heroine, Olivia, she seemed childish, and naive. Whereas, Bash has so much riding on his job, and seemed to be a stand up guy for his family until Olivia makes him lose his head. It just didn't click with me. The story, the characters, their circumstances and their chemistry. Something just seemed off.That being said, Fix You does have the potential to grow into a book I would like to read. It did end on a mild cliffhanger which will probably intrigue me enough to move on to the second book. But the second serial is going to have to possess major growth where Olivia is concerned, and more explanation where her family is concerned, and build more on Bash and Olivia's relationship. The way part one ended, it just felt like a physical connection with no deeper meaning between the two.Again, I don't mind serials but they have to be done fantastically. This one was just so-so, and the fact that it was a serial on top of that just made it more frustrating than anything. I want to be left needing and wanting more. Fix You just left me perplexed and wanting it to have gone the extra mile and reach its potential. I sincerely hope this was just a slow start and then next parts in the book will rise to the occasion.Happy Reading!*ARC provided by the author/publisher via NetGalley in exchange for an honest review*\nSupport Vector Machine:  ['POSITIVE']\nDecision Tree:  ['POSITIVE']\n-------\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "IndexError",
     "evalue": "list index out of range",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-86-f3999d2c788b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mid\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mtxt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_x\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mid\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mscr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_y\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mid\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscr\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'NEGATIVE'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "for id in range(1000):\n",
    "    txt = test_x[id]\n",
    "    scr = test_y[id]\n",
    "\n",
    "    if(scr == 'NEGATIVE'):\n",
    "        print(f'({id})', scr, ' / ', txt)\n",
    "        print('Support Vector Machine: ', clf_svm.predict(test_x_vectors[id]))\n",
    "        print('Decision Tree: ', clf_dtc.predict(test_x_vectors[id]))\n",
    "        print('-------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.8242424242424242\n0.7484848484848485\n0.8303030303030303\n"
     ]
    }
   ],
   "source": [
    "## Evaluation\n",
    "\n",
    "### Mean accuracy\n",
    "print(clf_svm.score(test_x_vectors, test_y))\n",
    "print(clf_dtc.score(test_x_vectors, test_y))\n",
    "#print(clf_gbn.score(test_x_vectors, test_y))\n",
    "print(clf_lr.score(test_x_vectors, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0.91319444 0.21052632 0.22222222]\n[0.85765125 0.15151515 0.0625    ]\n[0.91370558 0.12244898 0.1       ]\n"
     ]
    }
   ],
   "source": [
    "### F1 Score\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "print(f1_score(test_y, clf_svm.predict(test_x_vectors), average=None, labels=[Sentiment.POSITIVE, Sentiment.NEUTRAL, Sentiment.NEGATIVE]))\n",
    "\n",
    "print(f1_score(test_y, clf_dtc.predict(test_x_vectors), average=None, labels=[Sentiment.POSITIVE, Sentiment.NEUTRAL, Sentiment.NEGATIVE]))\n",
    "\n",
    "print(f1_score(test_y, clf_lr.predict(test_x_vectors), average=None, labels=[Sentiment.POSITIVE, Sentiment.NEUTRAL, Sentiment.NEGATIVE]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "47"
      ]
     },
     "metadata": {},
     "execution_count": 107
    }
   ],
   "source": [
    "train_y.count(Sentiment.NEGATIVE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}